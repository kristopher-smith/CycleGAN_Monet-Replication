{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GAN's From Scratch \n\nby Kris Smith","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement\n\n***This notebook is working towards generating images in the style of a famous artist painter [Claude Monet](https://en.wikipedia.org/wiki/Claude_Monet). This problem is presented as a competition on the Kaggle platform for the sake of learning. We will explore in particular one common approach to this task in the form of [Generative Adversarial Networks(GANs)](https://en.wikipedia.org/wiki/Generative_adversarial_network).***","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-18T18:20:57.026876Z","iopub.execute_input":"2023-06-18T18:20:57.027284Z","iopub.status.idle":"2023-06-18T18:21:05.483388Z","shell.execute_reply.started":"2023-06-18T18:20:57.027241Z","shell.execute_reply":"2023-06-18T18:21:05.482378Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Number of replicas: 1\n2.12.0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Overview\n\n### Dataset Description\n<i>The dataset contains four directories: monet_tfrec, photo_tfrec, monet_jpg, and photo_jpg. The monet_tfrec and monet_jpg directories contain the same painting images, and the photo_tfrec and photo_jpg directories contain the same photos.<i>\n\n<i>We recommend using TFRecords as a Getting Started competition is a great way to become more familiar with a new data format, but JPEG images have also been provided.\n\n<i>The monet directories contain Monet paintings. Use these images to train your model.\n\n<i>The photo directories contain photos. Add Monet-style to these images and submit your generated jpeg images as a zip file. Other photos outside of this dataset can be transformed but keep your submission file limited to 10,000 images.\n\n<i>Note: Monet-style art can be created from scratch using other GAN architectures like DCGAN. The submitted image files do not necessarily have to be transformed photos.\n\n<i>Check out the CycleGAN dataset to experiment with the artistic style of other artists.</i>\n\n    \n### Files\n* monet_jpg - 300 Monet paintings sized 256x256 in JPEG format\n* monet_tfrec - 300 Monet paintings sized 256x256 in TFRecord format\n* photo_jpg - 7028 photos sized 256x256 in JPEG format\n* photo_tfrec - 7028 photos sized 256x256 in TFRecord format\n\n### Submission format\n* Your kernel's output must be called images.zip and contain 7,000-10,000 images sized 256x256.\n    \n    \n### Evaluation\n    \nMiFID\n    \nSubmissions are evaluated on MiFID (Memorization-informed FrÃ©chet Inception Distance), which is a modification from FrÃ©chet Inception Distance (FID).\n\nThe smaller MiFID is, the better your generated images are.\n\nWhat is FID?\nOriginally published here (github), FID, along with Inception Score (IS), are both commonly used in recent publications as the standard for evaluation methods of GANs.\n\nIn FID, we use the Inception network to extract features from an intermediate layer. Then we model the data distribution for these features using a multivariate Gaussian distribution with mean Âµ and covariance Î£. The FID between the real images ğ‘Ÿ\n and generated images ğ‘”\n is computed as:\n$$\nFID = ||\\mu_{r} - \\mu_{g}||^{2} + Tr(\\Sigma_{r} + \\Sigma_{g} - 2(\\Sigma_{r}\\Sigma_{g})^{1/2})\n$$\n\n    \n    where ğ‘‡ğ‘Ÿ sums up all the diagonal elements. FID is calculated by computing the FrÃ©chet distance between two Gaussians fitted to feature representations of the Inception network.\n\nWhat is MiFID (Memorization-informed FID)?\nIn addition to FID, Kaggle takes training sample memorization into account.\n\nThe memorization distance is defined as the minimum cosine distance of all training samples in the feature space, averaged across all user generated image samples. This distance is thresholded, and it's assigned to 1.0 if the distance exceeds a pre-defined epsilon.\n\nIn mathematical form:\n    \n$$\nd_{ij} = 1 - \\cos(f_{gi}, f_{rj}) = 1 - \\frac{f_{gi} \\cdot f_{rj}}{||f_{gi}|| ||f_{rj}||}\n$$\n    \nwhere ğ‘“ğ‘”\n and ğ‘“ğ‘Ÿ\n represent the generated/real images in feature space (defined in pre-trained networks); and ğ‘“ğ‘”ğ‘–\n and ğ‘“ğ‘Ÿğ‘—\n represent the ğ‘–ğ‘¡â„\n and ğ‘—ğ‘¡â„\n vectors of ğ‘“ğ‘”\n and ğ‘“ğ‘Ÿ\n, respectively.\n\n$$\nd = \\frac{1}{N} \\sum_{i} \\min_{j} d_{ij}\n$$\n    \ndefines the minimum distance of a certain generated image (ğ‘–\n) across all real images ((ğ‘—\n), then averaged across all the generated images.\n\nenter image description here\ndefines the threshold of the weight only applies when the (ğ‘‘\n) is below a certain empirically determined threshold.\n\nFinally, this memorization term is applied to the FID:\n    \n$$\nMiFID = FID * \\frac{1}{d_thr}\n$$\n    \n**Kaggle's workflow calculating MiFID for public and private scores**\n    \nKaggle calculates public MiFID scores with the pre-train neural network Inception, and the public images used for evaluation are the rest of the TFDS Monet paintings. ***Note that as a Getting Started competition there is no private leaderboard.***\n\n    \n### Submission File\n    \nYou are going to generate 7,000-10,000 Monet-style images that are in jpg format. Their sizes should be 256x256x3 (RGB). Then you need to zip those images and your output from your Kernel should only have ONE output file named images.zip.\n\nPlease note that Kaggle Kernels has a number of output files capped at 500. We highly encourage you to either directly write to a zip file as you generate images, or create a folder at ../tmp as your temporary directory.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}